\documentclass[jou,apacite]{apa6}

\usepackage[utf8]{inputenc}
\usepackage[nonumberlist]{glossaries}
\usepackage{makeidx}

\makeglossaries
\loadglsentries{glossary}
\makeindex

\title{A short introduction to artificial intelligence}
\shorttitle{AI intro}

\author{Daniel Schruhl}
\affiliation{ThoughtWorks}

\abstract{A short introduction into the general topic of artificial intelligence. This should help address some aspects of artificial intelligence and define them on a shallow level to give a starting point into this topic.}

\begin{document}
\maketitle    
                        
\section{Motivation}
There are a lot of definitions for \gls{ai}. Most of them are based on a definition of intelligence which in itself is already difficult to define. A simple approach would be to say that humans cognitive functions (e.g. solving complex problems or learning) is considered intelligent. So making programs or machines pursue the way humans might solve problems or learn can be considered as \gls{ai}. These complex problems can be natural language processing, visual perception, motor control, planning or game theory.

\gls{ai} programs are sometimes also considered intelligent because from the outside their outcome appear to be magic. When actually developing the program itself and deep diving into the implementation, it leads to the realization of the often trivial nature of the implementation. This illustrates the possible paradox in \gls{ai}.

\gls{ai} can be used for image recognition, for controlling machines, to play games or to detect fraud. It can be used in nearly any domain and has already found great usage in medicine or commercial scenarios. Using \gls{ai} can give a company a major advantage against competitors. Companies like Netflix have embraced \gls{ai} \cite{Gomez-Uribe2015} and have established a market leading position also backed by \gls{ai}.

\section{Types of \gls{ai}}
Approaches to implement \gls{ai} have resulted into two major paradigms: \textbf{symbolic} and \textbf{sub-symbolic}. Symbolic approaches model a problem space with tokens or symbols that are humanly readable. This problem space is then processed by the \gls{ai} programs. The symbols themselves are therefore manipulated and processed. Because of the symbolic nature the \gls{ai} programs can be completely understood by humans. These programs are often called \gls{expert-system}, \gls{rules-engine}, \gls{knowledge-based-ai} or \gls{knowledge-graph}. They were the first paradigms that found usage in the past and are therefore also called \gls{gofai}. In theory they try to solve modeled problems in the same abstract way humans think and would solve problems.

The sub-symbolic paradigm also consists of symbols but they are not really human interpretable. These symbols represent more abstract components that can accomplish tasks suitable for \gls{ai} related tasks. The whole idea about this paradigm is to build the parts that make human cognitive functions possible on a more low level abstraction. It is highly inspired by biology (neurobiology, genetics, evolution) and psychology. This paradigm has found a lot of usage and popularity in the recent years.

\subsection{\gls{symbolic-ai}}
As stated before symbolic AI solves complex problems by using strategies researchers thought humans would also use. This is done by transforming a problem space into symbols and then applying functions on these symbols. The key here is coming up with an abstract model of the problem space and transforming it into symbols. Because of the nature of this paradigm, expert systems are easier to debug and understand and to control. A big disadvantage is that you need expert domain knowledge in order to solve the problem the way humans would do. Another advantage is though that big data is not needed.

Due to the symbolic nature \textbf{logic} can be used to solve complex problems. Logic consists of \textbf{semantic} and \textbf{syntax}. Syntax defines the representation of logics (symbols). It consists of an alphabet which forms words which in turn form language (\textbf{formulas}). This syntax is then interpreted by semantics. Semantics give meaning and interpretation to syntax and can be used to derive new formulas (\textbf{calculus}). This kind of system is called \textbf{formal system}. For more information about logics and formal systems see \cite{Richardson2006}. 

Formal systems have rules. These rules can be used to infer new rules or answer questions. This is often done by calculus (e.g. resolution calculus). Such a system of \gls{ai} can be built with \gls{prolog}. An example for this would be the task of parsing natural language into semantic compositions. Theoretical computer science can be used to define natural language with grammar. Inside that grammar are symbols like terminal and non-terminal symbols and productions which form rules. These rules can be used to parse natural language into semantic compositions like verbs, nouns or adjectives. These can in turn be used to be processed. This can be done with \textbf{\gls{dcg}} \cite{Wood1990}.

Another important aspect of symbolic AI are \textbf{searches}. In symbolic AI searches are used in finding solutions in a modeled problem space. The solution can be a path leading to a goal or the goal itself. The key aspect here is again modeling the problem space so a search is usable. This could be for example trying to find the perfect schedule for people with limited amount of time. Searches can be simple algorithms (breadth-first, depth-first) or \textbf{informed algorithms} (e.g. $A^*$). Informed algorithms use \textbf{heuristics} that try to estimate the best possible path inside a graph. This should lead to a faster search because some paths can be \textbf{pruned}. The intelligent part here lies in defining the heuristic. An example of an \gls{ai} using pruning and informed search is the Deep Blue chess computer \cite{Campbell2002}.

Another aspect in searches is the \textbf{\gls{csp}}. In a \gls{csp} are \textbf{variables} which have value spaces (\textbf{domains}). Each variable is attached to \textbf{constraints}. These constrains can have multiple arity and define limitations for the domains. 
This way a net of variables and constraints is formed (see figure \ref{fig:cs-net}). The problem of solving the net and narrowing down the domains to a solution is the actual \gls{csp}. To solve these problems there are multiple algorithms (e.g. AC-3). \gls{csp} can be used to solve riddles or puzzles like Sudoku.

\begin{figure}[!htb]
\centering
	\includegraphics[width=.25\textwidth]{csp.pdf}
\caption[Constraint net]{Constraint net with variables $v = \{X,Y,Z\}$ and constraints $c = \{C1, C2\}$. $C1 \mapsto X < Y$ and $C2 \mapsto X + Y = Z$. The domains for the variables are $D_X = \{1,2\}$, $D_Y = \{2,3,4\}$, $D_Z = \{4,7\}$. The solution would be $D_X = \{1\}$, $D_Y = \{3\}$, $D_Z = \{4\}$.}
\label{fig:cs-net}
\end{figure}

Searches can also be used to find paths from a start to a goal. This is called \textbf{planning}. In planning you have a state which describes a current situation. For the state there are possible moves that can be taken. Each move has a \textbf{condition}, \textbf{delete} and \textbf{add list}. Those lists can be used to test and execute the moves to change the state in order to pass the start state into the goal state. This kind of procedure can be used to control for example robotic arms. For more information see \gls{strips} and \cite{Nilsson1982}.

\subsection{\gls{sub-symbolic-ai}}
Sub-symbolic AI uses symbols in a more abstract way. The symbols become part of a low level system that is capable of cognitive functions. It is no longer possible to map concrete high level tasks like identifying objects in images directly to the symbols in the system. The output generated by sub-symbolic AI is therefore often probabilistic or approximated. This has led to more robust models that often showed better performance and scalability. Unfortunately most of these models need big data to get to that point. But these models are no longer bound to expert domain knowledge and have shown way better performance in tasks like visual perception. Sub-symbolic AI consists of machine learning, reinforcement learning and evolutionary computing.

\section{Machine learning}
Learning itself plays a huge part in cognitive functions. Learning essentially means incrementally improving performance on a given task. This implies that knowledge is represented in any form and incrementally more knowledge is generated or the already existing knowledge is hardened and diversified. Ways of achieving this would be by adding new data to that knowledge base or by adding time to extract more knowledge of the given knowledge base. Learning not only consists of extracting knowledge and retaining that knowledge of already learned data, but also means handling new data and transferring already learned knowledge (by \textbf{generalizing}).

Machine learning accomplishes learning by doing \textbf{pattern recognition} in (big) data and generalizing these patterns. 
Programs that actually perform machine learning are called \textbf{models}. Models use \textbf{input data} and \textbf{output data} (see figure \ref{fig:machine-learning-basic}). The input data contains \textbf{features}. Input data is used to input into the model. Output data is data that should or is output by the model. Machine learning models generate knowledge implicitly by the features of the input data. Machine learning tasks can be grouped into \textbf{supervised} and \textbf{unsupervised learning}.

\begin{figure}[!htb]
\centering
	\includegraphics[width=.4\textwidth]{machine-learning-basic.pdf}
\caption[Basic structure of machine learning]{Models use input data to produce output data. The model needs to be trained in order to generate knowledge from given data and generalize from it. The model can then be used to produce output on unseen input data (prediction).}
\label{fig:machine-learning-basic}
\end{figure}

In order to make models work they have to be trained on data. That data is separated into test and train data. The training data is used to feed the model with during training. The test data is used after training to see how well the model is able to generalize on unseen data. The most suggested train and test split is 80:20.

When training the model on the training data a metric called loss or error is calculated. This metric determines how far off the models output is from the original output (high loss or error). The goal of training is to minimize this metric. Depending on the error change rate (derivation) the parameters of the models are tuned to that error derivation. The model itself is therefore optimized through training.

After the training is done the test data can be used to determine if a model is underfitting or overfitting. These terms describe the generalizing capabilities of the model. Generalizing means that general abstract knowledge was generated from the trained on data (learning) and new unseen data can be processed by applying that general abstract knowledge on that data. This means that decisions and assumptions can be made on unseen data. Overfitting means, that the model started to memorize patterns in the data instead of generalizing from it. This can happen when the training is too long or the variance in the training data is not high enough. Underfitting means that the training error or loss has not been well enough optimized yet. This can happen when training is too short or not enough data has been seen.

\subsection{Supervised learning}
Supervised learning contains solutions for \textbf{classification} and \textbf{regression} tasks. For that input data with given output labels are needed. This kind of data is also called \textbf{labeled data}. For classification tasks a \textbf{decision boundary} is searched within the data. That decision boundary separates the input data into classes that should classify fish into sea bass or salmons (see figure \ref{fig:fish-classification}). To train this model labeled data of fish with the features length and skin brightness is used. For each data entry (one fish) the class sea bass or salmon (label) is already existent. The model then trains on this data and forms the decision boundary. If the model gets data of a new fish and its length and skin brightness, it will be able to identify the class this fish would be. It will predict if a fish is a salmon or a sea bass based on its length and skin brightness.

\begin{figure}[!htb]
\centering
\includegraphics[width=.45\textwidth]{classification-fish.png}
\caption[Classification of fish]{Classification of fish species dependent on their length and skin brightness. The classification model should learn the decision boundary (pink) to successfully distinguish between the two fish species.}
\label{fig:fish-classification}
\end{figure}

For regression tasks the features within the input data are used to approximate other variables for the output. The output itself is unlike to classification tasks \textbf{numerical values} and not classes. \textit{Numerical values (input) are therefore used to approximate the values of one or more other numerical values (output)}. An example for this would be the approximated prediction of mileage of cars dependent on their motor power and weight. The regression model would learn a function that approximates the mileage (output) dependent on the input data, which consists of motor power and weight. This model then learned to generalize by the given data and can be used to predict the mileage of new cars it has not seen before dependent on the knowledge it gained before (given data).

\subsection{Unsupervised learning}
Unsupervised learning is used to find patterns in data without labels (\textbf{unlabeled data}). The input data does not have labeled output data. This means that no interpretation can be concluded of the data. So using unsupervised learning is often also called \textbf{knowledge discovery}. In real life most existent data is unlabeled or partially labeled. This makes unsupervised learning very useful. Unsupervised learning can then be used to \textbf{cluster} data. This will group similar data input clusters. These clusters can then be further processed and put into classes for example.

\subsection{Connectionism}
\gls{connectionism} tries to solve complex problems by modeling what we use to solve problems - our brain. Neurobiologically the brain consists on a low level of \textbf{neurons} that are highly connected. These neurons are structured in \textbf{layers}. Subgroups of these layers can be mapped to individual tasks like hearing, controlling motor functions and more. The actual connections and the resulting topology highly specializes the actual function of each of these nets and their performance on different tasks. This can be modeled into a computer science abstraction.

\begin{figure}[!htb]
\centering
\includegraphics[width=.3\textwidth]{neuron.eps}
\caption[Computer science neuron abstraction]{Computer science model of a neuron. A neuron has incoming connections $a_0 ... a_i$. Each of those connections is weighted by $w_{0j} .. w_{ij}$. These connections and weights are multiplied and summed up in $\sum^{in_j}$. The output $a_j$ of this neuron is then calculated by applying the activation function $g$ on the sum $a_j = g(\sum^{in_j})$.}
\label{fig:neuron}
\end{figure}

A neural network is a \textbf{graph}. The nodes in this graph are called neurons. Each neuron has incoming \textbf{weighted connections}. These are used to calculate the \textbf{output} of each neuron (see figure \ref{fig:neuron}). The neurons are arranged in layers. Layers are just collections of neurons. A neural network trains by adjusting the weights of each connection with an algorithm called \textbf{backpropagation}. To speed up that process a optimization technique called \textbf{stochastic gradient descent} is used. The way the neurons are connected determines the topology and specification of that network. Different topologies are better at solving different tasks.

The simplest topology is a feedforward network. Feedforward networks are networks with input, hidden and output layers. The neurons of each layer are connected to each neuron of the following network. The connections are only in a feedforward direction. This is also called fully connected. These networks are good for not so complex tasks.

Another topology are recurrent neural nets. Recurrent neural nets have neurons in layers, that have connections from neurons from later layers or from themselves. This way it is possible to create a memory with the internal states of these neurons. This kind of topology has been shown promising when trying to process sequential data or time series data.

A similar topology are convolutional neural nets. convolutional neural nets have multidimensional input data (2D, e.g. pictures). They feed through that data with a reception field. This field is a smaller subset that is fed into parallel hidden layers that process that input data. Those hidden layers can then be connected to pooling layers that condense the parallel hidden layers and can in the end be fed into fully connected layers. This kind or architecture is great for learning from images or sequential data where neighboring data helds critical information.

//TODO: add network images

\subsection{Deep learning}
Machine learning algorithms perform bad on complex task with a \textbf{high dimensionality space}. This is due to the fact that with rising dimensionality the amount of possible combinations explode and the amount of available data to train on diminishes. \textit{The data density shrinks}. This is in contrast to the desired generalization. For generalization it is hard to find answers for data that is not at all represented in any way in the training data. To solve this problem deep learning was introduced. By adding more layers to a model and making the model deeper this way, the model is able to  learn more \textbf{abstract meta features} in the underlying training data. In this way \textbf{feature extraction} is being done automatically.

\section{Reinforcement learning}
Reinforcement learning is based on human psychology. A possible way humans might learn is by \textbf{rewards} or \textbf{penalization}. So learning is done by \textbf{reinforcement} (positive or negative). The model for this contains an \textbf{agent} that lives in an \textbf{environment} (see figure \ref{fig:reinforcement-learning}). The agent can take possible \textbf{actions} inside that environment. The actions then change the \textbf{state} of the environment. The result of that action is also a \textbf{reward}. This reward and the changed state are then perceived or processed by the agent. The agent tries to maximize the reward. Rewards are given by for example finding a goal. The agent has to run multiple \textbf{episodes}. Each episode contains a start and an end. On each start the state of the environment is reset. Eventually the agent should then learn the most optimal way to achieve a goal and solve a complex task.

\begin{figure}[!htb]
\centering
\includegraphics[width=.3\textwidth]{reinforcement-learning.pdf}
\caption[Model of reinforcement learning]{Model of reinforcement learning. An agent performs actions in an environment and receives rewards. The state of the environment gets changed as soon as the agent performed an action. The agent tries to optimize the reward.}
\label{fig:reinforcement-learning}
\end{figure}

In doing so an agent can either \textbf{exploit} or \textbf{explore}. Exploitation means the agent finds a way to get to the goal but starts to only replay this way of achieving the goal and might not find a more optimal path. Exploration means the agent tries out different paths to get to the goal and might not be able to find it. It is a trade off the agent has to do to be optimal. A way to overcome this problem is \textbf{Thompson Sampling} \cite{Chapelle2011}.

Some popular algorithms for reinforcement learning are \textbf{Q-Learning} \cite{Watkins1992} or \textbf{Sarsa} \cite{Berges1995}. Reinforcement learning was used in AlphaGo and AlphaZero \cite{silver2017}.

\section{Evolutionary computing}
TODO: EMMA
genetic algorithm, genetic programming, evolutionary programming

\section{Big Data in context}
TODO: Arif?

\section{Recent advances in machine learning and further topics}
 - capsule networks
 - autoencoders
 - attention mechanisms
 - gans
 - dqn
 - neat
 - neuroevolution

\section{Further readings}
To get into the basics deeper and to learn more about some neural network architectures refer to \cite{Goodfellow-et-al-2016}. This book is available online and contains nearly everything you need to know about neural nets and deep learning.

\printglossaries
\printindex
\bibliography{ai-intro-article}

\end{document}
